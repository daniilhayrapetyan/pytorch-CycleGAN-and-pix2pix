{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from models.resnet import ResnetGenerator, ResnetBlock, InverseTanh\n",
    "\n",
    "from tqdm import trange\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "import skimage\n",
    "import matplotlib.pyplot as plot\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = nn.Sequential(InverseTanh(),\n",
    "                                   nn.Conv2d(3, 40, 3, 2, 1),\n",
    "                                   ResnetBlock(40, 'zero', nn.BatchNorm2d, False, False),\n",
    "                                   nn.ConvTranspose2d(40, 3, 3, 2, 1),\n",
    "                                   nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetGenerator(3, 3)\n",
    "# model = CustomModel()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(n_input, n_output, kernel, stride, n_features):\n",
    "    weights = torch.randn([n_output, n_input, kernel[0], kernel[0]]) * 0.01\n",
    "    center = kernel[0] // 2\n",
    "    \n",
    "    assert stride[0] == stride[1]\n",
    "    assert kernel[0] == kernel[1]\n",
    "    s = stride[0]\n",
    "    for feature in range(n_features):\n",
    "        for i, j in np.ndindex(stride):\n",
    "            weights[feature*s*s + i*s + j, feature, center + i, center + j] = 1\n",
    "\n",
    "    return weights\n",
    "\n",
    "def compute_kernel_transpose(n_input, n_output, kernel, stride, n_features):\n",
    "    weights = torch.randn([n_input, n_output, kernel[0], kernel[0]]) * 0.01\n",
    "    center = kernel[0] // 2\n",
    "    \n",
    "    assert stride[0] == stride[1]\n",
    "    assert kernel[0] == kernel[1]\n",
    "    assert stride[0] < kernel[0]\n",
    "    \n",
    "    s = stride[0]\n",
    "    for feature in range(n_features//s//s):\n",
    "        for i, j in np.ndindex(stride):\n",
    "            weights[feature*s*s + i*s + j, feature,  center + i, center + j] = 1\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_resblock(layer):\n",
    "    layers = list(layer.conv_block.children())\n",
    "\n",
    "    nn.init.normal(layers[0].weight, 0.00, 0.01)\n",
    "    if layers[0].bias is not None: nn.init.constant(layers[0].bias, 0)\n",
    "    nn.init.constant(layers[1].weight, 1)\n",
    "    if layers[1].bias is not None: nn.init.constant(layers[1].bias, 0)\n",
    "    nn.init.normal(layers[3].weight, 0.00, 0.01)\n",
    "    if layers[3].bias is not None: nn.init.constant(layers[3].bias, 0)\n",
    "    nn.init.constant(layers[4].weight, 1)\n",
    "    nn.init.constant(layers[4].running_var, 1)\n",
    "    nn.init.constant(layers[4].running_mean, 0)\n",
    "    if layers[4].bias is not None: nn.init.constant(layers[4].bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_info = 3\n",
    "\n",
    "for layer in model.model.children():\n",
    "    if layer.__class__ == nn.BatchNorm2d:\n",
    "        nn.init.zeros_(layer.bias)\n",
    "        nn.init.ones_(layer.weight)\n",
    "        nn.init.zeros_(layer.running_mean)\n",
    "        nn.init.ones_(layer.running_var)\n",
    "    elif layer.__class__ == ResnetBlock:\n",
    "        zero_resblock(layer)\n",
    "    elif layer.__class__ == nn.Conv2d:\n",
    "        kernel = compute_kernel(layer.in_channels, layer.out_channels, \n",
    "                                layer.kernel_size, layer.stride, n_features_info)\n",
    "        layer.weight.data = kernel\n",
    "        if layer.bias is not None: nn.init.zeros_(layer.bias)\n",
    "        n_features_info *= layer.stride[0] * layer.stride[1]\n",
    "    elif layer.__class__ == nn.ConvTranspose2d:\n",
    "        kernel = compute_kernel_transpose(layer.in_channels, layer.out_channels, \n",
    "                                layer.kernel_size, layer.stride, n_features_info)\n",
    "        layer.weight.data = kernel\n",
    "        if layer.bias is not None: nn.init.zeros_(layer.bias)\n",
    "        n_features_info = n_features_info // (layer.stride[0] * layer.stride[1])\n",
    "        \n",
    "    print(\"{:<15} > {}\".format(layer.__class__.__name__, n_features_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.img_as_float(data.astronaut())\n",
    "\n",
    "image_t = torch.Tensor(image.transpose(2, 0, 1))[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_t1 = model.forward(image_t)\n",
    "image_1 = image_t1.detach().numpy()[0].transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.fromarray(skimage.img_as_ubyte(image_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.fromarray(skimage.img_as_ubyte(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Emotion-Transfer)",
   "language": "python",
   "name": "emotion-trasfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
