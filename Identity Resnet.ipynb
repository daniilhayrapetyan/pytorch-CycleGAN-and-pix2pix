{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from models.resnet import ResnetGenerator, ResnetBlock, InverseTanh\n",
    "\n",
    "from tqdm import trange\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from skimage import data\n",
    "import skimage\n",
    "import matplotlib.pyplot as plot\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = nn.Sequential(InverseTanh(),\n",
    "                                   nn.Conv2d(3, 40, 3, 2, 1),\n",
    "                                   ResnetBlock(40, 'zero', nn.BatchNorm2d, False, False),\n",
    "                                   nn.ConvTranspose2d(40, 3, 3, 2, 1),\n",
    "                                   nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResnetGenerator(3, 3)\n",
    "# model = CustomModel()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kernel(n_input, n_output, kernel, stride, n_features):\n",
    "    weights = torch.zeros([n_output, n_input, kernel[0], kernel[0]])\n",
    "    center = kernel[0] // 2\n",
    "    \n",
    "    assert stride[0] == stride[1]\n",
    "    assert kernel[0] == kernel[1]\n",
    "    s = stride[0]\n",
    "    for feature in range(n_features):\n",
    "        for i, j in np.ndindex(stride):\n",
    "            weights[feature*s*s + i*s + j, feature, center + i, center + j] = 1\n",
    "\n",
    "    return weights\n",
    "\n",
    "def compute_kernel_transpose(n_input, n_output, kernel, stride, n_features):\n",
    "    weights = torch.zeros([n_input, n_output, kernel[0], kernel[0]])\n",
    "    center = kernel[0] // 2\n",
    "    \n",
    "    assert stride[0] == stride[1]\n",
    "    assert kernel[0] == kernel[1]\n",
    "    assert stride[0] < kernel[0]\n",
    "    \n",
    "    s = stride[0]\n",
    "    for feature in range(n_features//s//s):\n",
    "        for i, j in np.ndindex(stride):\n",
    "            weights[feature*s*s + i*s + j, feature,  center + i, center + j] = 1\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_resblock(layer):\n",
    "    layers = list(layer.conv_block.children())\n",
    "\n",
    "    nn.init.normal(layers[0].weight, 0.00, 0.001)\n",
    "    if layers[0].bias is not None: nn.init.constant(layers[0].bias, 0)\n",
    "    nn.init.constant(layers[1].weight, 1)\n",
    "    if layers[1].bias is not None: nn.init.constant(layers[1].bias, 0)\n",
    "    nn.init.normal(layers[3].weight, 0.00, 0.001)\n",
    "    if layers[3].bias is not None: nn.init.constant(layers[3].bias, 0)\n",
    "    nn.init.constant(layers[4].weight, 1)\n",
    "    nn.init.constant(layers[4].running_var, 1)\n",
    "    nn.init.constant(layers[4].running_mean, 0)\n",
    "    if layers[4].bias is not None: nn.init.constant(layers[4].bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InverseTanh     > 3\n",
      "Conv2d          > 3\n",
      "BatchNorm2d     > 3\n",
      "ReLU            > 3\n",
      "Conv2d          > 12\n",
      "BatchNorm2d     > 12\n",
      "ReLU            > 12\n",
      "Conv2d          > 48\n",
      "BatchNorm2d     > 48\n",
      "ReLU            > 48\n",
      "ResnetBlock     > 48\n",
      "ResnetBlock     > 48\n",
      "ResnetBlock     > 48\n",
      "ResnetBlock     > 48\n",
      "ResnetBlock     > 48\n",
      "ResnetBlock     > 48\n",
      "ConvTranspose2d > 12\n",
      "BatchNorm2d     > 12\n",
      "ReLU            > 12\n",
      "ConvTranspose2d > 3\n",
      "BatchNorm2d     > 3\n",
      "ReLU            > 3\n",
      "Conv2d          > 3\n",
      "Tanh            > 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniilhayrapetyan/.virtualenvs/test/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/daniilhayrapetyan/.virtualenvs/test/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  \n",
      "/home/daniilhayrapetyan/.virtualenvs/test/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  import sys\n",
      "/home/daniilhayrapetyan/.virtualenvs/test/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  \n",
      "/home/daniilhayrapetyan/.virtualenvs/test/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/daniilhayrapetyan/.virtualenvs/test/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/daniilhayrapetyan/.virtualenvs/test/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  if sys.path[0] == '':\n",
      "/home/daniilhayrapetyan/.virtualenvs/test/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "n_features_info = 3\n",
    "\n",
    "for layer in model.model.children():\n",
    "    if layer.__class__ == nn.BatchNorm2d:\n",
    "        nn.init.zeros_(layer.bias)\n",
    "        nn.init.ones_(layer.weight)\n",
    "        nn.init.zeros_(layer.running_mean)\n",
    "        nn.init.ones_(layer.running_var)\n",
    "    elif layer.__class__ == ResnetBlock:\n",
    "        zero_resblock(layer)\n",
    "    elif layer.__class__ == nn.Conv2d:\n",
    "        kernel = compute_kernel(layer.in_channels, layer.out_channels, \n",
    "                                layer.kernel_size, layer.stride, n_features_info)\n",
    "        layer.weight.data = kernel\n",
    "        if layer.bias is not None: nn.init.zeros_(layer.bias)\n",
    "        n_features_info *= layer.stride[0] * layer.stride[1]\n",
    "    elif layer.__class__ == nn.ConvTranspose2d:\n",
    "        kernel = compute_kernel_transpose(layer.in_channels, layer.out_channels, \n",
    "                                layer.kernel_size, layer.stride, n_features_info)\n",
    "        layer.weight.data = kernel\n",
    "        if layer.bias is not None: nn.init.zeros_(layer.bias)\n",
    "        n_features_info = n_features_info // (layer.stride[0] * layer.stride[1])\n",
    "        \n",
    "    print(\"{:<15} > {}\".format(layer.__class__.__name__, n_features_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.img_as_float(data.astronaut())\n",
    "\n",
    "image_t = torch.Tensor(image.transpose(2, 0, 1))[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_t1 = model.forward(image_t)\n",
    "image_1 = image_t1.detach().numpy()[0].transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.fromarray(skimage.img_as_ubyte(image_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL.Image.fromarray(skimage.img_as_ubyte(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Emotion-Transfer)",
   "language": "python",
   "name": "emotion-trasfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
